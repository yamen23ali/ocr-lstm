{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/baseline')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from baseline_data_loader import load_data\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_char(indices):\n",
    "    chars = []\n",
    "    for indx in indices:\n",
    "        char_ord = ord('A') + indx\n",
    "        if indx < 26: chars.append(chr(char_ord))\n",
    "        else: chars.append(chr(char_ord + 6))\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, output_channels, kernel_size, alphabet_size, dropout_ratio):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        self.conv = torch.nn.Conv2d(1, output_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(8,10), stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(output_channels, output_channels, kernel_size=(4,2), stride=1, padding=0)\n",
    "        \n",
    "        \n",
    "        self.dropout = torch.nn.Dropout2d(p=dropout_ratio)\n",
    "        self.fc = torch.nn.Linear(output_channels * 26 * 5, alphabet_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(f'X shape is {x.shape}')\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        #print(f'Conv1 shape is {x.shape}')\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        #print(f'Pool shape is {x.shape}')\n",
    "        \n",
    "        #x = x.view(-1, self.output_channels, * 29 * 6)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        #print(f'Conv2 shape is {x.shape}')\n",
    "        \n",
    "        x = x.view(-1, self.output_channels * 26 * 5)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.fc(x)\n",
    "            \n",
    "    def custom_train(self, train_data, epochs, optimizer):\n",
    "        \n",
    "        training_losses = []\n",
    "        \n",
    "        for epoch in range(0,epochs):\n",
    "            epoch_loss = self._train_epoch(train_data, optimizer)\n",
    "            training_losses.append(epoch_loss)\n",
    "    \n",
    "            print(\"Epoch {}, Mean loss {}\".format(epoch, epoch_loss))\n",
    "            \n",
    "        return training_losses\n",
    "\n",
    "    def _train_epoch(self, train_data, optimizer):\n",
    "        losses = []\n",
    "\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_data, 0):\n",
    "            # Move data to GPU\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute output\n",
    "            x = batch['images']\n",
    "            output = self(x)\n",
    "\n",
    "            #Loss function\n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss(output, batch['labels_rep'])\n",
    "\n",
    "            # Compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            #torch.nn.utils.clip_grad_norm_(self.parameters(), clipping_value)\n",
    "\n",
    "            # Perform gradient descent\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track losses\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        return np.mean(losses) \n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.eval()\n",
    "        losses = list()\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        with torch.no_grad():  # Tell the model that we do not need gradient computation for evaluation\n",
    "            for i, batch in enumerate(test_loader, 0):\n",
    "                # Compute output\n",
    "                x = batch['images']\n",
    "                output = self(x)\n",
    "\n",
    "                # Loss function\n",
    "                loss = torch.nn.CrossEntropyLoss()\n",
    "                loss = loss(output, batch['labels_rep'])\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                prediction = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                print(\"=================\")\n",
    "                print(batch['labels'])\n",
    "                print(convert_to_char(prediction))\n",
    "                \n",
    "#                 correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "                \n",
    "                num_samples += len(x)         \n",
    "\n",
    "        # Compute average loss and accuracy\n",
    "        avg_loss = sum(losses) / len(losses) \n",
    "        accuracy = 0#correct / num_samples\n",
    "\n",
    "        return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Mean loss 3.957980519249326\n",
      "Epoch 1, Mean loss 3.95151918842679\n",
      "Epoch 2, Mean loss 3.950784424940745\n",
      "Epoch 3, Mean loss 3.9475746750831604\n",
      "Epoch 4, Mean loss 3.949395474933443\n",
      "Epoch 5, Mean loss 3.945285893621899\n",
      "Epoch 6, Mean loss 3.9379793405532837\n",
      "Epoch 7, Mean loss 3.930329061689831\n",
      "Epoch 8, Mean loss 3.9052100465411232\n",
      "Epoch 9, Mean loss 3.8809334692500888\n",
      "Epoch 10, Mean loss 3.8220817020961215\n",
      "Epoch 11, Mean loss 3.722071423417046\n",
      "Epoch 12, Mean loss 3.5878045984676907\n",
      "Epoch 13, Mean loss 3.445914938336327\n",
      "Epoch 14, Mean loss 3.2473289853050593\n",
      "Epoch 15, Mean loss 3.034092034612383\n",
      "Epoch 16, Mean loss 2.7917366453579495\n",
      "Epoch 17, Mean loss 2.6171473945890154\n",
      "Epoch 18, Mean loss 2.388335128625234\n",
      "Epoch 19, Mean loss 2.2241443267890384\n",
      "Epoch 20, Mean loss 2.198787726107098\n",
      "Epoch 21, Mean loss 2.0093348906153725\n",
      "Epoch 22, Mean loss 1.9314477571419306\n",
      "Epoch 23, Mean loss 1.8189680327971776\n",
      "Epoch 24, Mean loss 1.7725849563167209\n",
      "Epoch 25, Mean loss 1.743537296851476\n",
      "Epoch 26, Mean loss 1.672890210435504\n",
      "Epoch 27, Mean loss 1.7294409495024454\n",
      "Epoch 28, Mean loss 1.6339762728838694\n",
      "Epoch 29, Mean loss 1.6505357750824519\n",
      "Epoch 30, Mean loss 1.602980085249458\n",
      "Epoch 31, Mean loss 1.5358860443035762\n",
      "Epoch 32, Mean loss 1.5504012228477568\n",
      "Epoch 33, Mean loss 1.577436313033104\n",
      "Epoch 34, Mean loss 1.5319273659870738\n",
      "Epoch 35, Mean loss 1.4927378484890574\n",
      "Epoch 36, Mean loss 1.4600665416745913\n",
      "Epoch 37, Mean loss 1.5107163332757496\n",
      "Epoch 38, Mean loss 1.473754013578097\n",
      "Epoch 39, Mean loss 1.4153975684727942\n",
      "Epoch 40, Mean loss 1.4345263608154797\n",
      "Epoch 41, Mean loss 1.5161735259351277\n",
      "Epoch 42, Mean loss 1.4673140595356624\n",
      "Epoch 43, Mean loss 1.4136970976278895\n",
      "Epoch 44, Mean loss 1.4158610964105243\n",
      "Epoch 45, Mean loss 1.4608143688667388\n",
      "Epoch 46, Mean loss 1.3507959991693497\n",
      "Epoch 47, Mean loss 1.4256998321839742\n",
      "Epoch 48, Mean loss 1.4737022249471574\n",
      "Epoch 49, Mean loss 1.4382323803646224\n",
      "Epoch 50, Mean loss 1.4042385447592962\n",
      "Epoch 51, Mean loss 1.4103092813775653\n",
      "Epoch 52, Mean loss 1.3652205960381598\n",
      "Epoch 53, Mean loss 1.3182493512119566\n",
      "Epoch 54, Mean loss 1.3757581316999026\n",
      "Epoch 55, Mean loss 1.386440665594169\n",
      "Epoch 56, Mean loss 1.3592844896373295\n",
      "Epoch 57, Mean loss 1.3614963470470338\n",
      "Epoch 58, Mean loss 1.2807933630510455\n",
      "Epoch 59, Mean loss 1.3888516159994262\n",
      "Epoch 60, Mean loss 1.357274160853454\n",
      "Epoch 61, Mean loss 1.3305058081944783\n",
      "Epoch 62, Mean loss 1.2799463541734786\n",
      "Epoch 63, Mean loss 1.3219340940316517\n",
      "Epoch 64, Mean loss 1.376788015521708\n",
      "Epoch 65, Mean loss 1.3720131023299127\n",
      "Epoch 66, Mean loss 1.2996109912083262\n",
      "Epoch 67, Mean loss 1.2419249834049315\n",
      "Epoch 68, Mean loss 1.2975292170331592\n",
      "Epoch 69, Mean loss 1.3004516402170772\n",
      "Epoch 70, Mean loss 1.2632578909397125\n",
      "Epoch 71, Mean loss 1.34713293079819\n",
      "Epoch 72, Mean loss 1.3015810701818693\n",
      "Epoch 73, Mean loss 1.3143926245116053\n",
      "Epoch 74, Mean loss 1.2950357650184916\n",
      "Epoch 75, Mean loss 1.3031533573354994\n",
      "Epoch 76, Mean loss 1.2556777354329824\n",
      "Epoch 77, Mean loss 1.2835508279857182\n",
      "Epoch 78, Mean loss 1.2838484105609713\n",
      "Epoch 79, Mean loss 1.2140137939935638\n",
      "Epoch 80, Mean loss 1.218831182413158\n",
      "Epoch 81, Mean loss 1.2211727418360256\n",
      "Epoch 82, Mean loss 1.198292928437392\n",
      "Epoch 83, Mean loss 1.2746748392071043\n",
      "Epoch 84, Mean loss 1.282604913981188\n",
      "Epoch 85, Mean loss 1.21810079933632\n",
      "Epoch 86, Mean loss 1.2242832973244644\n",
      "Epoch 87, Mean loss 1.2573918506857895\n",
      "Epoch 88, Mean loss 1.1702914734681447\n",
      "Epoch 89, Mean loss 1.1971594151996432\n",
      "Epoch 90, Mean loss 1.2440819286164784\n",
      "Epoch 91, Mean loss 1.1960182126966261\n",
      "Epoch 92, Mean loss 1.2358202465942927\n",
      "Epoch 93, Mean loss 1.2008661971915335\n",
      "Epoch 94, Mean loss 1.254831404447378\n",
      "Epoch 95, Mean loss 1.3047585984071095\n",
      "Epoch 96, Mean loss 1.295603878441311\n",
      "Epoch 97, Mean loss 1.270083677910623\n",
      "Epoch 98, Mean loss 1.2610958910414152\n",
      "Epoch 99, Mean loss 1.2251466842634338\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMAGE_HEIGHT = 70\n",
    "IMAGE_WIDTH = 25\n",
    "ALPHABET_SIZE = 52\n",
    "OUTPUT_CHANNELS = 1 # filters number for conv layer\n",
    "DATASET_TRAIN_DIR='../synthetic/train/'\n",
    "DATASET_TEST_DIR='../synthetic/test/'\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "DROPOUT_RATIO=0.5\n",
    "\n",
    "model = BaselineCNN(OUTPUT_CHANNELS, (7, 5), ALPHABET_SIZE,DROPOUT_RATIO)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "train_data, test_data = load_data(DATASET_TRAIN_DIR, DATASET_TEST_DIR, 10, 10)\n",
    "\n",
    "loss = model.custom_train(train_data, EPOCHS, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = np.arange(0, EPOCHS)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.plot(x, loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['G', 'L', 'U', 'C', 'I', 'd', 'U', 'N', 'X', 'J']\n",
      "['G', 'E', 'U', 'C', 'I', 'd', 'U', 'N', 'X', 'J']\n",
      "=================\n",
      "['r', 'P', 't', 'O', 'B', 'G', 'v', 'N', 'U', 'n']\n",
      "['r', 'P', 't', 'O', 'B', 'G', 'v', 'N', 'U', 'n']\n",
      "=================\n",
      "['P', 'B', 's', 'U', 'f', 'R', 'B', 'o', 'I', 'W']\n",
      "['P', 'F', 's', 'U', 'f', 'R', 'B', 'o', 'v', 'F']\n",
      "=================\n",
      "['q', 'x', 'E', 'i', 'u', 'j', 'b', 'k', 'L', 'e']\n",
      "['q', 'x', 'E', 'i', 'u', 'j', 'b', 'k', 'E', 'e']\n",
      "=================\n",
      "['A', 'E', 'Z', 'k', 'A', 'K', 'I', 'a', 'i', 'e']\n",
      "['A', 'E', 'Z', 'k', 'A', 'K', 'I', 'a', 'i', 'e']\n",
      "=================\n",
      "['q', 's', 'U', 'S', 'T', 'K', 'J', 'j', 'c', 'a']\n",
      "['q', 's', 'U', 'S', 'T', 'k', 'J', 'j', 'c', 'a']\n",
      "=================\n",
      "['d', 'Y', 'n', 'W', 'g', 'Y', 'I', 'Q', 'W', 'm']\n",
      "['d', 'Y', 'n', 'W', 'g', 'V', 'I', 'Q', 'a', 'n']\n",
      "=================\n",
      "['w', 'F', 'R', 'S', 'Z', 'C', 's', 'b', 'C', 'f']\n",
      "['w', 'r', 'R', 'S', 'Z', 'C', 's', 'b', 'C', 'f']\n",
      "=================\n",
      "['G', 'a', 'L', 'V', 'C', 'l', 'M', 'b', 'S', 'x']\n",
      "['G', 'q', 'L', 'V', 'C', 'l', 'M', 'b', 'S', 'x']\n",
      "=================\n",
      "['n', 'Q', 'W', 'w', 'I', 'Q', 'T', 'M', 'o', 'n']\n",
      "['n', 'z', 'W', 'w', 'I', 'Q', 'T', 'M', 'x', 'x']\n",
      "=================\n",
      "['H', 'Z', 'h', 'o', 'X', 'C', 'E', 'z', 'm', 'O']\n",
      "['H', 'Z', 'h', 'o', 'X', 'C', 'E', 'r', 'm', 'O']\n",
      "=================\n",
      "['p', 'r', 'P', 'n', 'M', 'K', 'J', 'r', 'P', 'O']\n",
      "['p', 'r', 'P', 'n', 'R', 'K', 'J', 'r', 'E', 'O']\n",
      "=================\n",
      "['m', 'j', 'o', 'A', 'u', 'v', 'r', 'V', 'Z', 'G']\n",
      "['x', 'j', 'o', 'A', 'u', 'v', 'r', 'V', 'Z', 'C']\n",
      "=================\n",
      "['R', 'H', 'N', 'I', 'n', 'R', 'z', 'E', 'l', 'L']\n",
      "['R', 'H', 'N', 'I', 'n', 'R', 'z', 'E', 'T', 'L']\n",
      "=================\n",
      "['u', 'L', 'e', 'N', 'H', 'e', 'H', 'K', 'f', 'D']\n",
      "['q', 'L', 'e', 'N', 'w', 'c', 'H', 'K', 'i', 'D']\n",
      "=================\n",
      "['Y', 'y', 'B', 's', 'R', 'K', 'D', 'u', 'Y', 'J']\n",
      "['Y', 'y', 'B', 'z', 'R', 'K', 'D', 'u', 'Y', 'J']\n",
      "=================\n",
      "['O', 'x', 'q', 'H', 'h', 'I', 'N', 'q', 'l', 'd']\n",
      "['e', 'x', 'q', 'H', 'h', 'z', 'M', 'q', 'l', 'd']\n",
      "=================\n",
      "['R', 'P', 'v', 's', 'i', 'y', 'I', 't', 'u', 'L']\n",
      "['R', 'U', 'v', 'z', 'i', 'y', 'I', 'r', 'u', 'E']\n",
      "=================\n",
      "['m', 'd', 'g', 'W', 'v', 'h', 'S', 'O', 'u', 'Z']\n",
      "['n', 'd', 'g', 'x', 'v', 'h', 'S', 'O', 'n', 'Z']\n",
      "=================\n",
      "['l', 'o', 'n', 'F', 'G', 'W', 'B', 'o', 'd', 'X']\n",
      "['f', 'o', 'n', 'F', 'e', 'W', 'B', 'e', 'd', 'X']\n",
      "=================\n",
      "['W', 'h', 'i', 't', 'S', 'V', 'h', 'f', 'y', 'E']\n",
      "['W', 'h', 'i', 't', 'S', 'V', 'h', 'f', 'y', 'E']\n",
      "=================\n",
      "['B', 'L', 'h', 'z', 'J', 'Z', 'q', 'W', 'l', 'S']\n",
      "['B', 'E', 'h', 'z', 'T', 'Z', 'q', 'W', 'f', 'S']\n",
      "=================\n",
      "['D', 'U', 'k', 'G', 'j', 'p', 'Q', 'j', 'U', 'q']\n",
      "['D', 'U', 'k', 'G', 'j', 'p', 'Q', 'j', 'U', 'g']\n",
      "=================\n",
      "['u', 'G', 'k', 'x', 'F', 'F', 'g', 'V', 'Z', 'i']\n",
      "['u', 'f', 'k', 'x', 'F', 'E', 'g', 'V', 'Z', 'i']\n",
      "=================\n",
      "['m', 'e', 'Z', 'P', 'd', 'p', 'L', 'e', 'F', 'm']\n",
      "['m', 'c', 'Z', 'P', 'd', 'p', 'L', 'e', 'E', 'm']\n",
      "=================\n",
      "['H', 'C', 'S', 'C', 'D', 'b', 'o', 'u', 'H', 'n']\n",
      "['H', 'C', 'E', 'C', 'D', 'b', 'e', 'u', 'H', 'C']\n",
      "=================\n",
      "['k', 'A', 'P', 'r', 'O', 'f', 'T', 'i', 'F', 'L']\n",
      "['U', 'A', 'P', 'r', 'C', 'f', 'T', 'i', 'E', 'I']\n",
      "=================\n",
      "['I', 'O', 'i', 'p', 'W', 'M', 'T', 'Z', 'c', 'm']\n",
      "['T', 'O', 'l', 'p', 'W', 'M', 'T', 'j', 'c', 'n']\n",
      "=================\n",
      "['h', 'h', 'p', 'q', 'u', 'D', 'c', 'I', 'Q', 'W']\n",
      "['h', 'h', 'p', 'q', 'u', 'D', 'c', 'I', 'Q', 'W']\n",
      "=================\n",
      "['g', 'G', 'J', 'V', 'G', 'K', 'Q', 'a', 'r', 'a']\n",
      "['g', 'G', 'J', 'v', 'G', 'K', 'Q', 'a', 'r', 'a']\n",
      "=================\n",
      "['F', 'q', 'z', 's', 'a', 'p', 'Y', 'z', 'z', 'f']\n",
      "['F', 'q', 'z', 's', 'a', 'p', 'Y', 'z', 'z', 'f']\n",
      "=================\n",
      "['u', 'p', 'T', 'T', 'O', 'v', 'l', 'g', 't', 'L']\n",
      "['u', 'p', 'T', 'T', 'O', 'u', 'l', 'g', 't', 'E']\n",
      "=================\n",
      "['i', 'R', 'G', 'B', 'h', 'A', 'x', 'm', 'p', 'r']\n",
      "['i', 'R', 'G', 'G', 'h', 'Z', 'x', 'w', 'p', 'r']\n",
      "=================\n",
      "['K', 'q', 'D', 'g', 's', 'F', 'G', 'd', 'g', 'U']\n",
      "['z', 'q', 'D', 'g', 's', 'I', 'G', 'd', 'g', 'U']\n",
      "=================\n",
      "['y', 'N', 'X', 'a', 'T', 'H', 'm', 'Y', 'Q', 'n']\n",
      "['y', 'R', 'X', 'a', 'T', 'H', 'n', 'Y', 'Q', 'n']\n",
      "=================\n",
      "['O', 'l', 'B', 'b', 'P', 'r', 'r', 't', 'F', 'M']\n",
      "['O', 'l', 'B', 'b', 'P', 'r', 'r', 't', 'F', 'M']\n",
      "=================\n",
      "['j', 'X', 'p', 'U', 'H', 'N', 'o', 'e', 'z', 'S']\n",
      "['j', 'X', 'p', 'U', 'H', 'N', 'o', 'v', 'z', 'S']\n",
      "=================\n",
      "['i', 'w', 'f', 'b', 'x', 'o', 'H', 'R', 't', 'w']\n",
      "['i', 'w', 'j', 'd', 'x', 'o', 'H', 'R', 't', 'w']\n",
      "=================\n",
      "['W', 's', 'Y', 'g', 'O', 'J', 'Z', 'B', 'D', 'e']\n",
      "['W', 's', 'Y', 'g', 'O', 'J', 'h', 'B', 'D', 'i']\n",
      "=================\n",
      "['Q', 'D', 'w', 'W', 'm', 'W', 'E', 'M', 's', 'X']\n",
      "['Q', 'D', 'a', 'W', 'm', 'W', 'E', 'M', 's', 'X']\n",
      "=================\n",
      "['f', 'p', 'g', 'k', 'k', 'M', 'f', 'R', 'y', 'w']\n",
      "['f', 'p', 'g', 'k', 'k', 'M', 'i', 'R', 'y', 'u']\n",
      "=================\n",
      "['m', 'R', 'a', 'j', 'X', 'a', 'R', 'z', 'a', 'o']\n",
      "['n', 'R', 'u', 'j', 'X', 'x', 'R', 'z', 'a', 'o']\n",
      "=================\n",
      "['C', 'P', 'Z', 'K', 't', 'P', 't', 'F', 'n', 'c']\n",
      "['C', 'P', 'Z', 'K', 't', 'P', 't', 'F', 'n', 'c']\n",
      "=================\n",
      "['W', 'h', 'D', 'E', 'd', 'Z', 'v', 'C', 'b', 'S']\n",
      "['W', 'h', 'D', 'E', 'd', 'Z', 'v', 'C', 'h', 'Y']\n",
      "=================\n",
      "['M', 'F', 'q', 'f', 'T', 'K', 'G', 'E', 'm', 'v']\n",
      "['W', 'P', 'q', 'j', 'T', 'x', 'G', 'E', 'm', 'v']\n",
      "=================\n",
      "['O', 'w', 'Z', 'S', 'S', 'd', 'T', 'p', 'x', 'i']\n",
      "['O', 'w', 'Z', 'S', 'S', 'd', 'T', 'p', 'x', 'i']\n",
      "=================\n",
      "['A', 'L', 'A', 'r', 'z', 'c', 'V', 'u', 'C', 'l']\n",
      "['A', 'Z', 'R', 'r', 'z', 'c', 'V', 'v', 'C', 'l']\n",
      "=================\n",
      "['c', 'c', 'U', 't', 'Y', 'b', 'P', 'C', 'Q', 'T']\n",
      "['c', 'c', 'U', 't', 'Y', 'b', 'P', 'C', 'Q', 'E']\n",
      "=================\n",
      "['y', 'u', 'W', 'u', 'J', 'c', 'n', 'x', 'v', 'P']\n",
      "['y', 'u', 'W', 'u', 'J', 'c', 'n', 'x', 'v', 'P']\n",
      "=================\n",
      "['e', 'T', 'G', 'i', 'O', 'X', 'o', 'k', 'e', 'g']\n",
      "['e', 'T', 'G', 'i', 'O', 'X', 'o', 'k', 'o', 'g']\n",
      "=================\n",
      "['E', 'Z', 'G', 'd', 'B', 'N', 'x', 'F', 'p', 'F']\n",
      "['E', 'Z', 'G', 'd', 'B', 'N', 'x', 'F', 'p', 'F']\n",
      "=================\n",
      "['H', 'z', 'R', 'R', 'w', 'S', 'A', 'U', 'y', 'Q']\n",
      "['H', 'z', 'R', 'R', 'w', 'S', 'A', 'U', 'y', 'Q']\n",
      "=================\n",
      "['d', 'i', 'X', 'x', 'X', 'w', 'B', 'V', 'd', 'a']\n",
      "['d', 'f', 'X', 'x', 'X', 'w', 'B', 'i', 'd', 'a']\n",
      "=================\n",
      "['t', 'Y', 'D', 'H', 'N', 'c', 'o', 'X', 'f', 't']\n",
      "['t', 'Y', 'D', 'H', 'N', 'c', 'a', 'X', 'f', 'f']\n",
      "=================\n",
      "['u', 'H', 'Y', 'd', 'L', 'j', 'h', 'E', 'S', 'A']\n",
      "['u', 'H', 'Y', 'd', 'I', 'j', 'K', 'E', 'S', 'A']\n",
      "=================\n",
      "['Y', 'e', 'A', 'v', 'g', 'V', 'g', 'Y', 'k', 'j']\n",
      "['Y', 'c', 'A', 'v', 'j', 'V', 'g', 'Y', 'k', 'j']\n",
      "=================\n",
      "['p', 'w', 'q', 'O', 'y', 'b', 'b', 'E', 'u', 'N']\n",
      "['p', 'w', 'q', 'O', 'y', 'b', 'b', 'E', 'u', 'M']\n",
      "=================\n",
      "['y', 'J', 'V', 'L', 'q', 'v', 'S', 'b', 'x', 'R']\n",
      "['y', 'J', 'V', 'L', 'q', 'v', 'G', 'b', 'x', 'T']\n",
      "=================\n",
      "['f', 'N', 'D', 'D', 'b', 'F', 'J', 'V', 'M', 'D']\n",
      "['f', 'M', 'D', 'D', 'b', 'F', 'J', 'V', 'M', 'D']\n",
      "=================\n",
      "['X', 'b', 'c', 'x', 'I', 's', 'e', 'M', 'N', 'I']\n",
      "['X', 'h', 'c', 'w', 'I', 's', 'c', 'M', 'N', 'I']\n",
      "=================\n",
      "['o', 'a', 'w', 'C', 'a', 't', 'O', 'v', 'K', 'N']\n",
      "['o', 'a', 'w', 'C', 'a', 't', 'O', 'v', 'K', 'N']\n",
      "=================\n",
      "['B', 'm', 'k', 'D', 'x', 'g', 'g', 'V', 'r', 'P']\n",
      "['S', 'm', 'k', 'D', 'v', 'q', 'g', 'Y', 'r', 'p']\n",
      "=================\n",
      "['s', 'E', 'm', 'U', 't', 'l', 'l', 'n', 'y', 'r']\n",
      "['s', 'E', 'm', 'U', 't', 'l', 'l', 'n', 'y', 'r']\n",
      "=================\n",
      "['Y', 'o', 'A', 'e', 'r', 'c', 'o', 'T', 'k', 'D']\n",
      "['q', 's', 'A', 'c', 'x', 'c', 'o', 'T', 'k', 'D']\n",
      "=================\n",
      "['X', 'F', 'c', 'j', 'k', 'A', 'U', 'w', 'V', 'Q']\n",
      "['X', 'F', 'c', 'j', 'k', 'H', 'a', 'w', 'V', 'Q']\n",
      "=================\n",
      "['v', 'q', 't', 'a', 'S', 'I', 'i', 'l', 'Q', 'l']\n",
      "['c', 'q', 't', 'a', 'S', 'I', 'i', 'l', 'Q', 'I']\n",
      "=================\n",
      "['H', 'P', 's', 'x', 'Q', 'h', 't', 'B', 'z', 'd']\n",
      "['H', 'P', 's', 'x', 'Q', 'h', 't', 'B', 'z', 'd']\n",
      "=================\n",
      "['H', 'J', 'k', 'A', 'T', 'M', 'J', 'B', 'D', 'n']\n",
      "['H', 'J', 'k', 'A', 'I', 'M', 'J', 'B', 'r', 'n']\n",
      "=================\n",
      "['J', 'C', 'M', 'k', 'i', 'c', 'P', 'z', 'Y', 'K']\n",
      "['d', 'C', 'M', 'k', 'i', 'c', 'T', 'z', 'Y', 'K']\n",
      "=================\n",
      "['e', 'r', 'h', 'd', 'v', 'K', 'w', 'n', 'M', 'a']\n",
      "['c', 'r', 'h', 'J', 'v', 'K', 'w', 'w', 'M', 'a']\n",
      "=================\n",
      "['U', 'Q', 'c', 'H', 'z', 'i', 'r', 'z', 'L', 'k']\n",
      "['U', 'Q', 'c', 'H', 'z', 'i', 'p', 'z', 'L', 'k']\n",
      "=================\n",
      "['p', 'j', 'Z', 'y', 'a', 'j', 'J', 'V', 'p', 's']\n",
      "['p', 'j', 'Z', 'y', 'a', 'j', 'J', 'V', 'q', 's']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['C', 'j', 'I', 'A', 'J', 'b', 'V', 'R', 'M', 'y']\n",
      "['C', 'j', 'f', 'A', 'J', 'b', 'V', 'R', 'M', 'y']\n",
      "=================\n",
      "['v', 'h', 'J', 'N', 'N', 'f', 's', 'w', 'E', 'g']\n",
      "['a', 'k', 'O', 'N', 'N', 'f', 's', 'w', 'E', 'g']\n",
      "=================\n",
      "['i', 'h', 'b', 'p', 'j', 'Z', 'u', 'w', 'L', 'E']\n",
      "['i', 'h', 'F', 'p', 'j', 'Z', 'u', 'w', 'I', 'E']\n",
      "=================\n",
      "['Q', 'b', 'q', 's', 'j', 'E', 'q', 'G', 'f', 'K']\n",
      "['e', 'b', 'q', 's', 'j', 'E', 'q', 'G', 'f', 'K']\n",
      "=================\n",
      "['O', 'z', 's', 'U', 'C', 'T', 'Q', 'h', 'y', 'v']\n",
      "['O', 'z', 'r', 'U', 'C', 'T', 'Q', 'h', 'y', 'v']\n",
      "=================\n",
      "['F', 'S', 'j', 'y', 'n', 'x', 'G', 'Y', 'X', 'W']\n",
      "['F', 'S', 'j', 'y', 'n', 'x', 'G', 'Y', 'X', 'W']\n",
      "=================\n",
      "['T', 'e', 'V', 'e', 'I', 'f', 'q', 'X', 'L', 't']\n",
      "['T', 'e', 'V', 'e', 'l', 'f', 'q', 'X', 'E', 'e']\n",
      "=================\n",
      "['z', 'I', 'g', 'A', 'v', 'm', 'B', 'l', 'Y', 'C']\n",
      "['z', 'I', 'c', 'R', 'v', 'm', 'B', 'I', 'Y', 'C']\n",
      "=================\n",
      "['x', 'w', 'B', 'l', 'M', 'k', 'o', 'A', 'K', 'X']\n",
      "['x', 'w', 'g', 'l', 'M', 'k', 'e', 'A', 'K', 'X']\n",
      "=================\n",
      "['O', 'U', 'm', 'l', 'c', 'N', 'd', 'T', 'K', 'K']\n",
      "['O', 'U', 'm', 'l', 'c', 'N', 'd', 'T', 'K', 'K']\n",
      "=================\n",
      "['n', 'E', 'y', 'P', 'y', 'M', 'R', 'V', 'r', 'c']\n",
      "['n', 'E', 'y', 'P', 'q', 'M', 'R', 'I', 'r', 'c']\n",
      "=================\n",
      "['l', 'f']\n",
      "['I', 'f']\n",
      "Training set: \n",
      " \t Average loss: 0.6644, Accuracy: 0%\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss, train_accuracy = model.evaluate(train_data)\n",
    "print(f\"Training set: \\n \\t Average loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['y', 'M', 'B', 'w', 'b', 'Y', 'p', 'k', 'S', 'n']\n",
      "['Y', 'M', 'E', 'w', 'b', 'Y', 'p', 'k', 'S', 'a']\n",
      "=================\n",
      "['s', 'X', 'V', 'o', 'N', 'y', 'G', 'a', 'Z', 'u']\n",
      "['s', 'X', 'V', 'c', 'N', 'y', 'G', 'w', 'd', 'u']\n",
      "=================\n",
      "['B', 'M', 'P', 'Z', 'q', 'C', 'T', 'a', 'O', 'X']\n",
      "['B', 'M', 'T', 'Z', 'q', 'C', 'A', 'a', 'O', 'X']\n",
      "=================\n",
      "['I', 'h', 'f', 'x', 'g', 'Q', 'U', 'T', 'c', 'e']\n",
      "['T', 'Z', 'Z', 'w', 'g', 'O', 'U', 'T', 'c', 'e']\n",
      "=================\n",
      "['W', 'R', 'A', 'J', 'v', 'd', 'E', 'V', 'x', 'm']\n",
      "['W', 'R', 'A', 'U', 'v', 'd', 'F', 'V', 'x', 'm']\n",
      "=================\n",
      "['q', 'C', 'D', 'U', 'R', 'G', 'b', 'O', 'l', 'Y']\n",
      "['q', 'C', 'D', 'U', 'R', 'G', 'h', 'O', 'J', 'Y']\n",
      "=================\n",
      "['p', 't', 'H', 'H', 'n', 'd', 'e', 'h', 'z', 'm']\n",
      "['p', 'V', 'H', 'W', 'n', 'd', 'e', 'h', 'z', 'r']\n",
      "=================\n",
      "['k', 'u', 'S', 'Q', 's', 'N', 'g', 'K', 't', 'c']\n",
      "['A', 'u', 'Z', 'Q', 'z', 'N', 'g', 'K', 't', 'c']\n",
      "=================\n",
      "['L', 'i', 'r', 'F', 'J', 'A', 'F', 'v', 'j', 'w']\n",
      "['I', 'M', 'r', 'E', 'd', 'A', 'F', 'w', 'j', 'w']\n",
      "=================\n",
      "['r', 'K', 'I', 'W', 'l', 'f', 'E', 'z', 'i', 'D']\n",
      "['n', 'K', 'f', 'N', 'f', 'f', 'E', 'z', 'f', 'D']\n",
      "=================\n",
      "['o', 'j', 'P', 'L']\n",
      "['e', 'j', 'P', 'E']\n",
      "Test set: \n",
      " \t Average loss: 1.2571, Accuracy: 0%\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f\"Test set: \\n \\t Average loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
