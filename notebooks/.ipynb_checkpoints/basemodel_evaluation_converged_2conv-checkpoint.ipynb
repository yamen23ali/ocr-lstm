{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/baseline')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from baseline_data_loader import load_data\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_char(indices):\n",
    "    chars = []\n",
    "    for indx in indices:\n",
    "        char_ord = ord('A') + indx\n",
    "        if indx < 26: chars.append(chr(char_ord))\n",
    "        else: chars.append(chr(char_ord + 6))\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, output_channels, kernel_size, alphabet_size, dropout_ratio):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        \n",
    "        self.output_channels = output_channels\n",
    "        self.conv = torch.nn.Conv2d(1, output_channels, kernel_size=kernel_size, stride=1, padding=0)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(8,10), stride=2, padding=0)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(output_channels, output_channels, kernel_size=(4,2), stride=1, padding=0)\n",
    "        \n",
    "        \n",
    "        self.dropout = torch.nn.Dropout2d(p=dropout_ratio)\n",
    "        self.fc = torch.nn.Linear(output_channels * 26 * 5, alphabet_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(f'X shape is {x.shape}')\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        #print(f'Conv1 shape is {x.shape}')\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        #print(f'Pool shape is {x.shape}')\n",
    "        \n",
    "        #x = x.view(-1, self.output_channels, * 29 * 6)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        #print(f'Conv2 shape is {x.shape}')\n",
    "        \n",
    "        x = x.view(-1, self.output_channels * 26 * 5)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.fc(x)\n",
    "            \n",
    "    def custom_train(self, train_data, epochs, optimizer):\n",
    "        \n",
    "        training_losses = []\n",
    "        \n",
    "        for epoch in range(0,epochs):\n",
    "            epoch_loss = self._train_epoch(train_data, optimizer)\n",
    "            training_losses.append(epoch_loss)\n",
    "    \n",
    "            print(\"Epoch {}, Mean loss {}\".format(epoch, epoch_loss))\n",
    "            \n",
    "        return training_losses\n",
    "\n",
    "    def _train_epoch(self, train_data, optimizer):\n",
    "        losses = []\n",
    "\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_data, 0):\n",
    "            # Move data to GPU\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute output\n",
    "            x = batch['images']\n",
    "            output = self(x)\n",
    "\n",
    "            #Loss function\n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            loss = loss(output, batch['labels_rep'])\n",
    "\n",
    "            # Compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            #torch.nn.utils.clip_grad_norm_(self.parameters(), clipping_value)\n",
    "\n",
    "            # Perform gradient descent\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track losses\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        return np.mean(losses) \n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.eval()\n",
    "        losses = list()\n",
    "        correct = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        with torch.no_grad():  # Tell the model that we do not need gradient computation for evaluation\n",
    "            for i, batch in enumerate(test_loader, 0):\n",
    "                # Compute output\n",
    "                x = batch['images']\n",
    "                output = self(x)\n",
    "\n",
    "                # Loss function\n",
    "                loss = torch.nn.CrossEntropyLoss()\n",
    "                loss = loss(output, batch['labels_rep'])\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                prediction = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                char_predictions  = convert_to_char(prediction)\n",
    "                #print(\"=================\")\n",
    "                #print(batch['labels'])\n",
    "                #print(char_predictions)\n",
    "                \n",
    "                correct +=  np.sum(np.array(batch['labels']) == np.array(char_predictions))\n",
    "                \n",
    "                num_samples += len(x)         \n",
    "\n",
    "        # Compute average loss and accuracy\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        accuracy = (correct*100) / num_samples\n",
    "\n",
    "        return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Mean loss 3.953823458580744\n",
      "Epoch 1, Mean loss 3.952904857340313\n",
      "Epoch 2, Mean loss 3.951577132656461\n",
      "Epoch 3, Mean loss 3.948620793365297\n",
      "Epoch 4, Mean loss 3.943791292962574\n",
      "Epoch 5, Mean loss 3.9405014429773604\n",
      "Epoch 6, Mean loss 3.9307426867030917\n",
      "Epoch 7, Mean loss 3.9025926930563792\n",
      "Epoch 8, Mean loss 3.867460628350576\n",
      "Epoch 9, Mean loss 3.7761858134042647\n",
      "Epoch 10, Mean loss 3.581532066776639\n",
      "Epoch 11, Mean loss 3.465379391397749\n",
      "Epoch 12, Mean loss 3.2568173777489435\n",
      "Epoch 13, Mean loss 3.0622834307806834\n",
      "Epoch 14, Mean loss 2.946716163839613\n",
      "Epoch 15, Mean loss 2.8363491623174575\n",
      "Epoch 16, Mean loss 2.7382446186883107\n",
      "Epoch 17, Mean loss 2.637345778090613\n",
      "Epoch 18, Mean loss 2.5512211805298213\n",
      "Epoch 19, Mean loss 2.548423232067199\n",
      "Epoch 20, Mean loss 2.4143532713254294\n",
      "Epoch 21, Mean loss 2.326385109197526\n",
      "Epoch 22, Mean loss 2.301245983157839\n",
      "Epoch 23, Mean loss 2.3105496012029194\n",
      "Epoch 24, Mean loss 2.2688366841702234\n",
      "Epoch 25, Mean loss 2.1761781019823894\n",
      "Epoch 26, Mean loss 2.1118664840857186\n",
      "Epoch 27, Mean loss 2.064909490801039\n",
      "Epoch 28, Mean loss 2.0878938209442865\n",
      "Epoch 29, Mean loss 2.063205007995878\n",
      "Epoch 30, Mean loss 1.989322861745244\n",
      "Epoch 31, Mean loss 1.969094026656378\n",
      "Epoch 32, Mean loss 1.9338200503871554\n",
      "Epoch 33, Mean loss 1.9675642989930653\n",
      "Epoch 34, Mean loss 1.892246683438619\n",
      "Epoch 35, Mean loss 1.815941219528516\n",
      "Epoch 36, Mean loss 1.7953010165975207\n",
      "Epoch 37, Mean loss 1.894367040622802\n",
      "Epoch 38, Mean loss 1.8303939749797185\n",
      "Epoch 39, Mean loss 1.771446474960872\n",
      "Epoch 40, Mean loss 1.810419350152924\n",
      "Epoch 41, Mean loss 1.7479110055026554\n",
      "Epoch 42, Mean loss 1.6812770778224582\n",
      "Epoch 43, Mean loss 1.6688585040115176\n",
      "Epoch 44, Mean loss 1.7228885222048986\n",
      "Epoch 45, Mean loss 1.7397970748799187\n",
      "Epoch 46, Mean loss 1.678768434694835\n",
      "Epoch 47, Mean loss 1.6005464785155796\n",
      "Epoch 48, Mean loss 1.6234898340134394\n",
      "Epoch 49, Mean loss 1.6321461165235156\n",
      "Epoch 50, Mean loss 1.6527656518987246\n",
      "Epoch 51, Mean loss 1.5454855809609096\n",
      "Epoch 52, Mean loss 1.5925407941852296\n",
      "Epoch 53, Mean loss 1.6078168536935533\n",
      "Epoch 54, Mean loss 1.56348131668\n",
      "Epoch 55, Mean loss 1.5909294383156867\n",
      "Epoch 56, Mean loss 1.506429557998975\n",
      "Epoch 57, Mean loss 1.5077559359016872\n",
      "Epoch 58, Mean loss 1.5599120018028079\n",
      "Epoch 59, Mean loss 1.5467371096213658\n",
      "Epoch 60, Mean loss 1.4286041415873028\n",
      "Epoch 61, Mean loss 1.511301064420314\n",
      "Epoch 62, Mean loss 1.5386192089035398\n",
      "Epoch 63, Mean loss 1.466641447373799\n",
      "Epoch 64, Mean loss 1.4978762517372768\n",
      "Epoch 65, Mean loss 1.4628655470552898\n",
      "Epoch 66, Mean loss 1.4513263752063115\n",
      "Epoch 67, Mean loss 1.5074910010610307\n",
      "Epoch 68, Mean loss 1.5036327420246034\n",
      "Epoch 69, Mean loss 1.4529464961517424\n",
      "Epoch 70, Mean loss 1.433437817508266\n",
      "Epoch 71, Mean loss 1.5458293280431203\n",
      "Epoch 72, Mean loss 1.4891625188645863\n",
      "Epoch 73, Mean loss 1.3937921602101553\n",
      "Epoch 74, Mean loss 1.3567460005482037\n",
      "Epoch 75, Mean loss 1.3968107753566332\n",
      "Epoch 76, Mean loss 1.4533652301345552\n",
      "Epoch 77, Mean loss 1.3335502403123038\n",
      "Epoch 78, Mean loss 1.4007977708464576\n",
      "Epoch 79, Mean loss 1.474987947515079\n",
      "Epoch 80, Mean loss 1.3668909881796156\n",
      "Epoch 81, Mean loss 1.4095869156576337\n",
      "Epoch 82, Mean loss 1.3889301075112253\n",
      "Epoch 83, Mean loss 1.3619658095496041\n",
      "Epoch 84, Mean loss 1.3637633298834164\n",
      "Epoch 85, Mean loss 1.3948617669798078\n",
      "Epoch 86, Mean loss 1.4610172637871333\n",
      "Epoch 87, Mean loss 1.3507070243358612\n",
      "Epoch 88, Mean loss 1.4159484874634516\n",
      "Epoch 89, Mean loss 1.3502527950775056\n",
      "Epoch 90, Mean loss 1.3994493668987638\n",
      "Epoch 91, Mean loss 1.337507501954124\n",
      "Epoch 92, Mean loss 1.3615796150905746\n",
      "Epoch 93, Mean loss 1.3809639971171106\n",
      "Epoch 94, Mean loss 1.3982657059317543\n",
      "Epoch 95, Mean loss 1.3394713231495448\n",
      "Epoch 96, Mean loss 1.2971599811599368\n",
      "Epoch 97, Mean loss 1.283520953995841\n",
      "Epoch 98, Mean loss 1.363591302008856\n",
      "Epoch 99, Mean loss 1.3355101297299068\n",
      "Epoch 100, Mean loss 1.3439272613752455\n",
      "Epoch 101, Mean loss 1.3570885707934697\n",
      "Epoch 102, Mean loss 1.3355590857210613\n",
      "Epoch 103, Mean loss 1.3033619505308924\n",
      "Epoch 104, Mean loss 1.2618715496999877\n",
      "Epoch 105, Mean loss 1.3279846370929764\n",
      "Epoch 106, Mean loss 1.3790292562473387\n",
      "Epoch 107, Mean loss 1.3500080960137504\n",
      "Epoch 108, Mean loss 1.3228907758990924\n",
      "Epoch 109, Mean loss 1.2605214047999609\n",
      "Epoch 110, Mean loss 1.2655247116372699\n",
      "Epoch 111, Mean loss 1.3801648006552742\n",
      "Epoch 112, Mean loss 1.2861982171113293\n",
      "Epoch 113, Mean loss 1.3549725078046322\n",
      "Epoch 114, Mean loss 1.288939882247221\n",
      "Epoch 115, Mean loss 1.3170901316972006\n",
      "Epoch 116, Mean loss 1.3957719543860072\n",
      "Epoch 117, Mean loss 1.267020278033756\n",
      "Epoch 118, Mean loss 1.261477591026397\n",
      "Epoch 119, Mean loss 1.2957508156430864\n",
      "Epoch 120, Mean loss 1.3045678053583418\n",
      "Epoch 121, Mean loss 1.2573458609126864\n",
      "Epoch 122, Mean loss 1.2536455779558136\n",
      "Epoch 123, Mean loss 1.3022990496385665\n",
      "Epoch 124, Mean loss 1.264736865957578\n",
      "Epoch 125, Mean loss 1.2319680203994114\n",
      "Epoch 126, Mean loss 1.258399595107351\n",
      "Epoch 127, Mean loss 1.3396931680895032\n",
      "Epoch 128, Mean loss 1.2827825876218932\n",
      "Epoch 129, Mean loss 1.3039131132619721\n",
      "Epoch 130, Mean loss 1.2728632596277056\n",
      "Epoch 131, Mean loss 1.228524346436773\n",
      "Epoch 132, Mean loss 1.2856516373299418\n",
      "Epoch 133, Mean loss 1.2066255227795668\n",
      "Epoch 134, Mean loss 1.2975812675874858\n",
      "Epoch 135, Mean loss 1.262346924770446\n",
      "Epoch 136, Mean loss 1.229612549500806\n",
      "Epoch 137, Mean loss 1.20086477377585\n",
      "Epoch 138, Mean loss 1.1731332279741764\n",
      "Epoch 139, Mean loss 1.229330731644517\n",
      "Epoch 140, Mean loss 1.1865970480832315\n",
      "Epoch 141, Mean loss 1.2890004693042665\n",
      "Epoch 142, Mean loss 1.2090008652635984\n",
      "Epoch 143, Mean loss 1.2444659925642467\n",
      "Epoch 144, Mean loss 1.225117557815143\n",
      "Epoch 145, Mean loss 1.289731923313368\n",
      "Epoch 146, Mean loss 1.2430253468808674\n",
      "Epoch 147, Mean loss 1.2378680170291947\n",
      "Epoch 148, Mean loss 1.2176698960718655\n",
      "Epoch 149, Mean loss 1.3304529502278282\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMAGE_HEIGHT = 70\n",
    "IMAGE_WIDTH = 25\n",
    "ALPHABET_SIZE = 52\n",
    "OUTPUT_CHANNELS = 1 # filters number for conv layer\n",
    "DATASET_TRAIN_DIR='../synthetic/train/'\n",
    "DATASET_TEST_DIR='../synthetic/test/'\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "DROPOUT_RATIO=0.5\n",
    "\n",
    "model = BaselineCNN(OUTPUT_CHANNELS, (7, 5), ALPHABET_SIZE,DROPOUT_RATIO)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "train_data, test_data = load_data(DATASET_TRAIN_DIR, DATASET_TEST_DIR, 10, 10)\n",
    "\n",
    "loss = model.custom_train(train_data, EPOCHS, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = np.arange(0, EPOCHS)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.plot(x, loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['H', 'G', 's', 'k', 'z', 'n', 'v', 'u', 'e', 'k']\n",
      "['H', 'G', 's', 'k', 'z', 'u', 'v', 'u', 'a', 'k']\n",
      "=================\n",
      "['V', 'G', 'n', 'L', 'a', 'z', 'I', 'D', 'm', 'o']\n",
      "['V', 'G', 'n', 'L', 'a', 'z', 'I', 'D', 'm', 'o']\n",
      "=================\n",
      "['s', 'O', 'Q', 'e', 'j', 'T', 'o', 'T', 'R', 'O']\n",
      "['s', 'O', 'C', 'e', 'j', 'T', 'o', 'T', 'R', 'O']\n",
      "=================\n",
      "['c', 'H', 'S', 'v', 'y', 'h', 'Q', 'w', 'c', 'o']\n",
      "['g', 'H', 'S', 'v', 'y', 'h', 'Q', 'a', 'e', 's']\n",
      "=================\n",
      "['P', 'm', 'H', 'E', 'H', 'q', 'd', 'P', 'n', 'B']\n",
      "['P', 'm', 'H', 'E', 'H', 'q', 'd', 'P', 'n', 'R']\n",
      "=================\n",
      "['X', 'X', 'N', 'D', 'S', 'p', 'S', 'b', 'N', 'k']\n",
      "['X', 'X', 'N', 'D', 'S', 'p', 'S', 'b', 'N', 'k']\n",
      "=================\n",
      "['t', 't', 'H', 'H', 'X', 'A', 'l', 'i', 'w', 'W']\n",
      "['t', 't', 'H', 'H', 'X', 'A', 'l', 'i', 'w', 'W']\n",
      "=================\n",
      "['b', 'u', 'H', 'o', 'b', 'I', 'A', 'F', 'F', 'g']\n",
      "['b', 'm', 'T', 'o', 'b', 'I', 'A', 'F', 'F', 'g']\n",
      "=================\n",
      "['Z', 'j', 'Q', 'S', 'Q', 'H', 'v', 'o', 's', 'd']\n",
      "['Z', 't', 'Q', 'G', 'Q', 'H', 'v', 'o', 's', 'd']\n",
      "=================\n",
      "['M', 'E', 'w', 'V', 'c', 'i', 'G', 'U', 'T', 'A']\n",
      "['H', 'E', 'w', 'V', 'o', 'i', 'G', 'U', 'T', 'A']\n",
      "=================\n",
      "['j', 'T', 'q', 'K', 'J', 'a', 'd', 'C', 'p', 'R']\n",
      "['j', 'T', 'q', 'K', 'f', 'a', 'd', 'C', 'p', 'R']\n",
      "=================\n",
      "['Z', 'F', 'k', 'y', 'f', 'o', 'G', 'Y', 'm', 'f']\n",
      "['Q', 'F', 'k', 'y', 'W', 'o', 'G', 'Y', 'm', 'P']\n",
      "=================\n",
      "['K', 'R', 'u', 'C', 'Y', 'T', 'n', 'u', 'I', 'H']\n",
      "['K', 'R', 'u', 'C', 'Y', 'T', 'n', 'n', 'I', 'H']\n",
      "=================\n",
      "['t', 't', 'e', 'u', 'd', 'V', 'd', 'a', 'U', 'r']\n",
      "['s', 't', 'a', 'u', 'd', 'V', 'd', 'a', 'U', 'r']\n",
      "=================\n",
      "['o', 'n', 't', 'x', 'j', 'g', 'r', 'y', 'X', 'V']\n",
      "['o', 'n', 't', 'v', 'D', 'g', 'r', 'y', 'X', 'V']\n",
      "=================\n",
      "['K', 'G', 'p', 'd', 'i', 'V', 'T', 'q', 'P', 'Y']\n",
      "['K', 'G', 'p', 'w', 'i', 'V', 'T', 'q', 'P', 'Y']\n",
      "=================\n",
      "['N', 'U', 'Q', 'z', 'A', 'P', 'F', 'G', 'V', 'L']\n",
      "['N', 'U', 'Q', 'z', 'A', 'P', 'F', 'G', 'V', 'L']\n",
      "=================\n",
      "['h', 'w', 'W', 'R', 'T', 'z', 'I', 'B', 'V', 'U']\n",
      "['h', 's', 'H', 'R', 'T', 'z', 'I', 'B', 'V', 'U']\n",
      "=================\n",
      "['J', 'n', 'g', 'k', 'A', 'c', 'S', 'd', 's', 'F']\n",
      "['J', 'n', 'g', 'k', 'A', 'c', 'S', 'd', 's', 'F']\n",
      "=================\n",
      "['l', 'M', 'k', 'N', 'Y', 'I', 'Z', 'J', 'n', 'Z']\n",
      "['i', 'M', 'k', 'N', 'Y', 'I', 'Z', 'J', 'n', 'Z']\n",
      "=================\n",
      "['j', 'o', 'M', 'r', 'I', 'H', 'H', 'C', 'p', 'f']\n",
      "['j', 'o', 'M', 'r', 'l', 'Q', 'H', 'C', 'p', 'C']\n",
      "=================\n",
      "['x', 'j', 'J', 'j', 'U', 'T', 'u', 'i', 's', 'o']\n",
      "['x', 'j', 'J', 'j', 'U', 'T', 'q', 'i', 's', 'o']\n",
      "=================\n",
      "['R', 'h', 'G', 'O', 'M', 'h', 'D', 'h', 'c', 'T']\n",
      "['R', 'h', 'G', 'O', 'X', 'h', 'D', 'h', 'o', 'T']\n",
      "=================\n",
      "['z', 'j', 'N', 'P', 's', 'I', 'e', 'Y', 'X', 'P']\n",
      "['z', 'j', 'X', 'P', 's', 'I', 'e', 'Y', 'X', 'P']\n",
      "=================\n",
      "['I', 'g', 'f', 'B', 'l', 'b', 'v', 'C', 'n', 'M']\n",
      "['D', 'g', 'f', 'B', 'i', 'b', 'v', 'C', 'n', 'M']\n",
      "=================\n",
      "['V', 'P', 'r', 'c', 'E', 'e', 'M', 'R', 'F', 'W']\n",
      "['V', 'D', 'r', 'o', 'E', 'e', 'M', 'R', 'F', 'W']\n",
      "=================\n",
      "['T', 'l', 'n', 'v', 'B', 'Y', 'a', 'H', 'Q', 'c']\n",
      "['T', 'l', 'n', 'v', 'B', 'G', 'a', 'H', 'Q', 'g']\n",
      "=================\n",
      "['j', 'p', 't', 'x', 'l', 'u', 'O', 'b', 'W', 'U']\n",
      "['j', 'p', 'r', 'x', 'l', 'u', 'O', 'b', 'W', 'U']\n",
      "=================\n",
      "['E', 'f', 'r', 'f', 'k', 'y', 'v', 'm', 's', 'D']\n",
      "['A', 'i', 'r', 'f', 'k', 'y', 'v', 'n', 's', 'D']\n",
      "=================\n",
      "['a', 'K', 'l', 'f', 'S', 'K', 'i', 'm', 'a', 'R']\n",
      "['a', 'K', 'I', 'f', 'S', 'K', 'i', 'm', 'a', 'R']\n",
      "=================\n",
      "['C', 'C', 'C', 'b', 'v', 'K', 'U', 'L', 'j', 'K']\n",
      "['C', 'C', 'C', 'b', 'v', 'K', 'U', 'L', 'j', 'K']\n",
      "=================\n",
      "['x', 'W', 'h', 'K', 'u', 'z', 'B', 'R', 'G', 'P']\n",
      "['x', 'H', 'A', 'K', 'w', 'z', 'B', 'R', 'R', 'P']\n",
      "=================\n",
      "['p', 'w', 't', 'g', 'q', 'c', 'r', 'S', 'N', 'h']\n",
      "['p', 'w', 't', 'g', 'q', 'c', 'r', 'S', 'B', 'h']\n",
      "=================\n",
      "['p', 'R', 'Z', 'y', 'D', 'm', 't', 'y', 'C', 'i']\n",
      "['p', 'R', 'Z', 'y', 'D', 'm', 't', 'y', 'C', 'i']\n",
      "=================\n",
      "['N', 'F', 'J', 's', 'E', 'w', 'O', 'f', 'O', 'P']\n",
      "['N', 'F', 'J', 's', 'E', 'w', 'O', 'f', 'O', 'P']\n",
      "=================\n",
      "['c', 'E', 'E', 'P', 'J', 'v', 'G', 'c', 'Z', 't']\n",
      "['a', 'T', 'E', 'P', 'J', 'u', 'G', 'o', 'Z', 't']\n",
      "=================\n",
      "['a', 'b', 'o', 'G', 'u', 'G', 'a', 'I', 'h', 'M']\n",
      "['z', 'f', 'o', 'G', 'u', 'G', 'a', 'I', 'h', 'T']\n",
      "=================\n",
      "['O', 'a', 'J', 'm', 'F', 'Y', 'M', 'L', 'f', 'r']\n",
      "['O', 'a', 'J', 'm', 'F', 'V', 'M', 'L', 'f', 'r']\n",
      "=================\n",
      "['f', 'd', 'o', 'q', 'X', 'b', 'B', 'v', 'q', 'e']\n",
      "['f', 'd', 's', 'q', 'X', 'b', 'B', 'v', 'q', 'e']\n",
      "=================\n",
      "['U', 'A', 'L', 'c', 'E', 'h', 'W', 'A', 'X', 'c']\n",
      "['U', 'A', 'L', 'x', 'R', 'h', 'W', 'A', 'X', 'o']\n",
      "=================\n",
      "['T', 'F', 'G', 'x', 'o', 'r', 'Q', 'Z', 'W', 'v']\n",
      "['D', 'F', 'G', 'x', 'o', 'r', 'Q', 'Z', 'W', 'v']\n",
      "=================\n",
      "['J', 'E', 'r', 'q', 'B', 'j', 'n', 'J', 't', 'R']\n",
      "['J', 'E', 'r', 'q', 'B', 'j', 'n', 'J', 't', 'R']\n",
      "=================\n",
      "['A', 'd', 'y', 'k', 'w', 'Q', 'D', 'q', 'L', 'g']\n",
      "['A', 'd', 'y', 'k', 'w', 'Q', 'D', 'q', 'L', 'g']\n",
      "=================\n",
      "['I', 'X', 'n', 'e', 'X', 'l', 'S', 'C', 'N', 'n']\n",
      "['I', 'R', 'n', 'K', 'X', 'I', 'S', 'C', 'N', 'n']\n",
      "=================\n",
      "['m', 'J', 'W', 'i', 'l', 's', 'f', 'I', 'S', 't']\n",
      "['m', 'J', 'N', 'i', 'I', 's', 'f', 'R', 'S', 't']\n",
      "=================\n",
      "['B', 'e', 'D', 'S', 'r', 'g', 'j', 'g', 'l', 'r']\n",
      "['B', 'e', 'D', 'S', 'r', 'z', 'j', 'g', 'I', 'r']\n",
      "=================\n",
      "['C', 'k', 'C', 'l', 'v', 'c', 'q', 'W', 'U', 'J']\n",
      "['C', 'k', 'C', 'X', 'v', 'c', 'p', 'H', 'U', 'J']\n",
      "=================\n",
      "['v', 'F', 'F', 'Z', 'Z', 'o', 'h', 'y', 'O', 'Z']\n",
      "['v', 'F', 'F', 'Z', 'Z', 'o', 'h', 'y', 'O', 'Z']\n",
      "=================\n",
      "['U', 'b', 'M', 'z', 'J', 'W', 'Q', 'p', 'C', 'p']\n",
      "['U', 'b', 'M', 'z', 'J', 'H', 'Q', 'p', 'C', 'p']\n",
      "=================\n",
      "['S', 'h', 'g', 'E', 'H', 'r', 'M', 'n', 's', 'N']\n",
      "['B', 'h', 'g', 'E', 'H', 'r', 'M', 'n', 's', 'T']\n",
      "=================\n",
      "['b', 'u', 'Q', 'Y', 'y', 'e', 'w', 'L', 'y', 'Z']\n",
      "['b', 'Q', 'Q', 'X', 'y', 'e', 'n', 'L', 'y', 'A']\n",
      "=================\n",
      "['Y', 'f', 'z', 'O', 'P', 'G', 'P', 'z', 'b', 'Q']\n",
      "['Y', 'J', 'z', 'O', 'P', 'G', 'P', 'z', 'b', 'Q']\n",
      "=================\n",
      "['h', 'k', 'f', 'B', 'h', 'i', 'G', 'X', 's', 's']\n",
      "['h', 'k', 'f', 'B', 'h', 't', 'G', 'N', 's', 'n']\n",
      "=================\n",
      "['X', 'b', 'q', 'x', 'O', 'K', 'y', 'R', 'K', 'I']\n",
      "['X', 'b', 'q', 'x', 'O', 'K', 'y', 'R', 'K', 'I']\n",
      "=================\n",
      "['w', 'k', 'v', 'l', 'w', 'D', 'K', 'B', 'w', 'M']\n",
      "['w', 'k', 'v', 'l', 'w', 'D', 'K', 'B', 'e', 'M']\n",
      "=================\n",
      "['s', 'y', 'C', 'G', 'M', 'e', 'a', 'J', 'D', 'U']\n",
      "['s', 'y', 'C', 'R', 'N', 'n', 'a', 'd', 'D', 'U']\n",
      "=================\n",
      "['L', 'y', 'g', 'K', 'W', 'E', 'h', 'k', 'X', 'I']\n",
      "['L', 'y', 'g', 'k', 'n', 'E', 'h', 'k', 'X', 'I']\n",
      "=================\n",
      "['j', 'L', 'B', 'd', 'p', 'V', 'U', 'w', 'a', 'T']\n",
      "['j', 'L', 'B', 'd', 'p', 'V', 'A', 'w', 'a', 'T']\n",
      "=================\n",
      "['q', 'A', 'p', 'f', 'C', 'R', 'r', 'R', 'E', 'z']\n",
      "['q', 'A', 'p', 'f', 'G', 'R', 'x', 'R', 'E', 'e']\n",
      "=================\n",
      "['u', 'a', 'L', 'a', 'D', 'I', 'g', 'M', 'x', 'j']\n",
      "['q', 'a', 'L', 'a', 'D', 'l', 'r', 'M', 'x', 'j']\n",
      "=================\n",
      "['x', 'n', 'e', 'P', 'O', 'X', 'S', 'R', 'Q', 'M']\n",
      "['x', 'n', 'e', 'P', 'O', 'X', 'S', 'R', 'Q', 'H']\n",
      "=================\n",
      "['I', 'V', 'x', 'x', 'l', 'p', 'p', 'p', 'b', 'j']\n",
      "['W', 'V', 'x', 'x', 'i', 'p', 'p', 'p', 'b', 'j']\n",
      "=================\n",
      "['i', 'Z', 'Y', 'w', 'n', 'L', 'u', 'l', 'g', 'q']\n",
      "['i', 'Z', 'Y', 'n', 'n', 'I', 'n', 'I', 'g', 'q']\n",
      "=================\n",
      "['U', 'l', 'h', 'M', 'x', 'm', 'K', 'J', 'U', 'R']\n",
      "['C', 'I', 'h', 'M', 'x', 'm', 'K', 'J', 'V', 'B']\n",
      "=================\n",
      "['Y', 'w', 'G', 'E', 'O', 'z', 't', 'o', 'm', 'j']\n",
      "['Y', 'w', 'G', 'E', 'O', 'z', 'i', 'o', 'm', 'j']\n",
      "=================\n",
      "['x', 'A', 'D', 'd', 'W', 'z', 'e', 'L', 'Y', 'g']\n",
      "['x', 'A', 'D', 'd', 'W', 'y', 'e', 'A', 'Y', 'g']\n",
      "=================\n",
      "['u', 'S', 'b', 'V', 'P', 'f', 'k', 'm', 'T', 'd']\n",
      "['n', 'S', 'b', 'J', 'P', 'i', 'k', 'm', 'I', 'd']\n",
      "=================\n",
      "['Q', 'T', 'L', 'A', 'w', 'k', 'U', 'z', 'u', 'l']\n",
      "['Q', 'T', 'L', 'A', 'w', 'k', 'U', 'z', 'u', 'l']\n",
      "=================\n",
      "['Z', 'V', 'd', 'H', 'Y', 'R', 'C', 'N', 'b', 'x']\n",
      "['Z', 'V', 'd', 'H', 'Y', 'R', 'C', 'R', 'b', 'x']\n",
      "=================\n",
      "['o', 'v', 'm', 'A', 'W', 'X', 'S', 'r', 'q', 'X']\n",
      "['o', 's', 'm', 'A', 'W', 'X', 'B', 'r', 'q', 'X']\n",
      "=================\n",
      "['s', 'k', 'g', 'c', 'A', 'H', 'D', 'r', 'z', 'D']\n",
      "['s', 'k', 'p', 'o', 'A', 'H', 'D', 'r', 'z', 'b']\n",
      "=================\n",
      "['B', 'K', 'a', 'S', 'E', 't', 'i', 'z', 'B', 'v']\n",
      "['B', 'X', 'a', 'S', 'E', 't', 'i', 'z', 'B', 'v']\n",
      "=================\n",
      "['c', 'D', 'Z', 't', 'v', 'S', 'y', 'V', 'y', 'W']\n",
      "['g', 'D', 'R', 't', 'v', 'S', 'y', 'V', 'y', 'H']\n",
      "=================\n",
      "['i', 'i', 'b', 'g', 'M', 'O', 'k', 'T', 'B', 'i']\n",
      "['i', 'i', 'b', 'g', 'N', 'O', 'f', 'T', 'B', 'i']\n",
      "=================\n",
      "['x', 'D', 'A', 'W', 'x', 'q', 'm', 'F', 'Q', 'F']\n",
      "['x', 'D', 'A', 'W', 'x', 'q', 'n', 'F', 'Q', 'F']\n",
      "=================\n",
      "['P', 'm', 'E', 'V', 'L', 'm', 'e', 'o', 'N', 'Z']\n",
      "['P', 'm', 'H', 'V', 'L', 'm', 'e', 'o', 'N', 'T']\n",
      "=================\n",
      "['n', 'I', 'B', 'e', 'J', 'T', 'J', 'i', 'K', 'q']\n",
      "['n', 'I', 'B', 'e', 'J', 'T', 'J', 'i', 'K', 'q']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['N', 'V', 'A', 't', 'O', 'Y', 'y', 'p', 'r', 'm']\n",
      "['N', 'V', 'A', 't', 'O', 'Y', 'y', 'p', 'v', 'n']\n",
      "=================\n",
      "['f', 'c', 'd', 'F', 'E', 'w', 'W', 'K', 'C', 'N']\n",
      "['F', 'o', 'J', 'F', 'H', 'w', 'W', 'K', 'C', 'N']\n",
      "=================\n",
      "['N', 't', 'Y', 'F', 'Z', 'e', 'Q', 'L', 'i', 'i']\n",
      "['X', 't', 'X', 'F', 'Z', 'c', 'O', 'L', 'i', 'i']\n",
      "=================\n",
      "['P', 'g', 'u', 'e', 'A', 'B', 's', 'u', 'l', 'O']\n",
      "['P', 'g', 'u', 'a', 'A', 'B', 's', 'v', 'l', 'O']\n",
      "=================\n",
      "['d', 'a', 'z', 'F', 'd', 'N', 'H', 'x', 'Q', 'N']\n",
      "['d', 'n', 'w', 'F', 'd', 'N', 'H', 'x', 'Q', 'N']\n",
      "=================\n",
      "['L', 'a', 'U', 's', 'X', 'D', 'q', 'V', 'h', 'O']\n",
      "['L', 's', 'U', 's', 'X', 'D', 'q', 'V', 'b', 'O']\n",
      "=================\n",
      "['p', 'Y']\n",
      "['p', 'Y']\n",
      "Training set: \n",
      " \t Average loss: 0.6431, Accuracy: 82%\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss, train_accuracy = model.evaluate(train_data)\n",
    "print(f\"Training set: \\n \\t Average loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "['J', 'R', 'U', 'I', 'U', 's', 'H', 'b', 'i', 'F']\n",
      "['J', 'B', 'U', 'I', 'U', 'o', 'H', 'b', 'i', 'R']\n",
      "=================\n",
      "['V', 'q', 'T', 'A', 'q', 'g', 'n', 'y', 'u', 'X']\n",
      "['V', 'q', 'D', 'K', 'q', 'q', 'n', 'y', 'w', 'N']\n",
      "=================\n",
      "['x', 'e', 'w', 'a', 'm', 'N', 'a', 'C', 't', 'J']\n",
      "['s', 'e', 'w', 'a', 'n', 'M', 'o', 'O', 't', 'C']\n",
      "=================\n",
      "['O', 'D', 'G', 's', 'p', 'f', 'Y', 'R', 'K', 'S']\n",
      "['O', 'D', 'G', 'n', 'p', 'f', 'X', 'R', 'K', 'S']\n",
      "=================\n",
      "['Q', 'Q', 'W', 'k', 'c', 'V', 'K', 'z', 'O', 'F']\n",
      "['D', 'O', 'R', 'k', 'O', 'H', 'N', 'w', 'O', 'F']\n",
      "=================\n",
      "['M', 'M', 'h', 'G', 'l', 'W', 'g', 'j', 'Z', 'j']\n",
      "['M', 'X', 'b', 'G', 'R', 'W', 'g', 'B', 'H', 'j']\n",
      "=================\n",
      "['z', 'u', 'D', 'o', 'Y', 'H', 'N', 'L', 'k', 'B']\n",
      "['z', 'w', 'D', 'o', 'Y', 'H', 'N', 'L', 'A', 'B']\n",
      "=================\n",
      "['v', 'Z', 'P', 'E', 'f', 'd', 'n', 'x', 'h', 'E']\n",
      "['v', 'k', 'P', 'R', 'T', 'B', 'm', 'x', 'h', 'B']\n",
      "=================\n",
      "['m', 'v', 'L', 'y', 'e', 'T', 'o', 'r', 'I', 'A']\n",
      "['w', 'v', 'T', 'f', 'n', 'R', 'm', 'r', 'A', 'R']\n",
      "=================\n",
      "['c', 'C', 'l', 'r', 'p', 'b', 't', 'S', 'd', 'P']\n",
      "['o', 'C', 'I', 'R', 'p', 'D', 'v', 'G', 'd', 'P']\n",
      "=================\n",
      "['i', 'w', 'X', 'B']\n",
      "['A', 'w', 'X', 'B']\n",
      "Test set: \n",
      " \t Average loss: 1.7543, Accuracy: 51%\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f\"Test set: \\n \\t Average loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../trained_models/56_acc')\n",
    "#model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
