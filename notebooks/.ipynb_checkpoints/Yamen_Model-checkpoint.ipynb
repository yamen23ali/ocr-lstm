{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from ocr_data_loader import load_data\n",
    "from ocr_utils import *\n",
    "from ocr_model import OCRModel\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/ocr_model.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor( batch[1]['text_vector'] )\n",
      "../src/ocr_model.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_lengths = torch.tensor( batch[1]['text_length'] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Mean loss 0.18370480835437775\n",
      "Epoch 1, Mean loss 0.18401667475700378\n",
      "Epoch 2, Mean loss 0.18396171927452087\n",
      "Epoch 3, Mean loss 0.20243465900421143\n",
      "Epoch 4, Mean loss 0.20291832089424133\n",
      "Epoch 5, Mean loss 0.18236330151557922\n",
      "Epoch 6, Mean loss 0.18220485746860504\n",
      "Epoch 7, Mean loss 0.18132363259792328\n",
      "Epoch 8, Mean loss 0.20160581171512604\n",
      "Epoch 9, Mean loss 0.18078778684139252\n",
      "Epoch 10, Mean loss 0.18130645155906677\n",
      "Epoch 11, Mean loss 0.18029743432998657\n",
      "Epoch 12, Mean loss 0.18127988278865814\n",
      "Epoch 13, Mean loss 0.18109656870365143\n",
      "Epoch 14, Mean loss 0.18081340193748474\n",
      "Epoch 15, Mean loss 0.18109065294265747\n",
      "Epoch 16, Mean loss 0.20007583498954773\n",
      "Epoch 17, Mean loss 0.18025022745132446\n",
      "Epoch 18, Mean loss 0.18003442883491516\n",
      "Epoch 19, Mean loss 0.2002863883972168\n",
      "Epoch 20, Mean loss 0.17937038838863373\n",
      "Epoch 21, Mean loss 0.18015418946743011\n",
      "Epoch 22, Mean loss 0.1801353394985199\n",
      "Epoch 23, Mean loss 0.1792815774679184\n",
      "Epoch 24, Mean loss 0.17913874983787537\n",
      "Epoch 25, Mean loss 0.17918458580970764\n",
      "Epoch 26, Mean loss 0.19844911992549896\n",
      "Epoch 27, Mean loss 0.1988992840051651\n",
      "Epoch 28, Mean loss 0.17980262637138367\n",
      "Epoch 29, Mean loss 0.17960764467716217\n",
      "Epoch 30, Mean loss 0.19922621548175812\n",
      "Epoch 31, Mean loss 0.19878491759300232\n",
      "Epoch 32, Mean loss 0.17806677520275116\n",
      "Epoch 33, Mean loss 0.17758873105049133\n",
      "Epoch 34, Mean loss 0.17797838151454926\n",
      "Epoch 35, Mean loss 0.17822828888893127\n",
      "Epoch 36, Mean loss 0.19828206300735474\n",
      "Epoch 37, Mean loss 0.17692658305168152\n",
      "Epoch 38, Mean loss 0.17776891589164734\n",
      "Epoch 39, Mean loss 0.17776846885681152\n",
      "Epoch 40, Mean loss 0.19654396176338196\n",
      "Epoch 41, Mean loss 0.17796435952186584\n",
      "Epoch 42, Mean loss 0.17633368074893951\n",
      "Epoch 43, Mean loss 0.1770906150341034\n",
      "Epoch 44, Mean loss 0.17720244824886322\n",
      "Epoch 45, Mean loss 0.1764981895685196\n",
      "Epoch 46, Mean loss 0.17626634240150452\n",
      "Epoch 47, Mean loss 0.1771458089351654\n",
      "Epoch 48, Mean loss 0.1755053997039795\n",
      "Epoch 49, Mean loss 0.17625373601913452\n",
      "Epoch 50, Mean loss 0.176682248711586\n",
      "Epoch 51, Mean loss 0.17624925076961517\n",
      "Epoch 52, Mean loss 0.1956654191017151\n",
      "Epoch 53, Mean loss 0.17559842765331268\n",
      "Epoch 54, Mean loss 0.1952986866235733\n",
      "Epoch 55, Mean loss 0.1754617989063263\n",
      "Epoch 56, Mean loss 0.19647032022476196\n",
      "Epoch 57, Mean loss 0.1757981777191162\n",
      "Epoch 58, Mean loss 0.17414650321006775\n",
      "Epoch 59, Mean loss 0.17506518959999084\n",
      "Epoch 60, Mean loss 0.1743415892124176\n",
      "Epoch 61, Mean loss 0.1744903028011322\n",
      "Epoch 62, Mean loss 0.17476806044578552\n",
      "Epoch 63, Mean loss 0.17461667954921722\n",
      "Epoch 64, Mean loss 0.17379513382911682\n",
      "Epoch 65, Mean loss 0.17427779734134674\n",
      "Epoch 66, Mean loss 0.17326734960079193\n",
      "Epoch 67, Mean loss 0.17418846487998962\n",
      "Epoch 68, Mean loss 0.175056591629982\n",
      "Epoch 69, Mean loss 0.1735396385192871\n",
      "Epoch 70, Mean loss 0.1726844608783722\n",
      "Epoch 71, Mean loss 0.17351466417312622\n",
      "Epoch 72, Mean loss 0.1734764724969864\n",
      "Epoch 73, Mean loss 0.17317353188991547\n",
      "Epoch 74, Mean loss 0.19306258857250214\n",
      "Epoch 75, Mean loss 0.17368873953819275\n",
      "Epoch 76, Mean loss 0.17303882539272308\n",
      "Epoch 77, Mean loss 0.173258975148201\n",
      "Epoch 78, Mean loss 0.174393892288208\n",
      "Epoch 79, Mean loss 0.17241880297660828\n",
      "Epoch 80, Mean loss 0.19209414720535278\n",
      "Epoch 81, Mean loss 0.17312517762184143\n",
      "Epoch 82, Mean loss 0.17161063849925995\n",
      "Epoch 83, Mean loss 0.17183765769004822\n",
      "Epoch 84, Mean loss 0.1715887486934662\n",
      "Epoch 85, Mean loss 0.19139447808265686\n",
      "Epoch 86, Mean loss 0.17165417969226837\n",
      "Epoch 87, Mean loss 0.17192445695400238\n",
      "Epoch 88, Mean loss 0.1904386579990387\n",
      "Epoch 89, Mean loss 0.17233452200889587\n",
      "Epoch 90, Mean loss 0.17255030572414398\n",
      "Epoch 91, Mean loss 0.1715344488620758\n",
      "Epoch 92, Mean loss 0.17093417048454285\n",
      "Epoch 93, Mean loss 0.17048385739326477\n",
      "Epoch 94, Mean loss 0.17103800177574158\n",
      "Epoch 95, Mean loss 0.1708448827266693\n",
      "Epoch 96, Mean loss 0.1914314180612564\n",
      "Epoch 97, Mean loss 0.1708136647939682\n",
      "Epoch 98, Mean loss 0.1703050583600998\n",
      "Epoch 99, Mean loss 0.17180703580379486\n",
      "Final Mean loss 0.17180703580379486\n",
      "============== Infer test data\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0c93c19a779f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mpredicted_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQUENCES_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_DIMENSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Text{} \\n Predicted Text {} \\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../../GT4HistOCR/corpus'\n",
    "DATA_SET_NAME = 'RefCorpus-ENHG-Incunabula/1476-Historij-Wierstaat'\n",
    "\n",
    "#========= Hyper parameters \n",
    "\n",
    "# Image parameters\n",
    "IMAGE_WIDTH = 70\n",
    "IMAGE_HEIGHT = 700\n",
    "SEQUENCES_NUM = 20 # Number of input sequences ( i.e.: How many frames we will split the input image into)\n",
    "\n",
    "# NN parameters\n",
    "HIDDEN_LAYER_SIZE = 500\n",
    "HIDDEN_LAYERS_NUM = 1 # Number of LSTM cells to stack\n",
    "\n",
    "# Training parameters\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.05\n",
    "EPOCHS = 100\n",
    "TRAIN_TEST_SPLIT = .8\n",
    "CLIPPING_VALUE = 3\n",
    "\n",
    "transformation = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(-90,-90), expand=True), \n",
    "     transforms.Resize((IMAGE_HEIGHT,IMAGE_WIDTH)), \n",
    "     transforms.ToTensor()])\n",
    "\n",
    "train_data, test_data, dataset = load_data(base_dir = '../GT4HistOCR/corpus', dataset_name = 'RefCorpus-ENHG-Incunabula/1476-Historij-Wierstaat',\n",
    "                                              transformation=transformation,\n",
    "                                              train_test_split=TRAIN_TEST_SPLIT)\n",
    "\n",
    "# Fixed values ( i.e.: not configurable)\n",
    "ALPHABET_SIZE = len(dataset.alphabet)\n",
    "INPUT_DIMENSION = int( (IMAGE_HEIGHT / SEQUENCES_NUM) * IMAGE_WIDTH )\n",
    "\n",
    "\n",
    "# Define and train the model\n",
    "model = OCRModel(INPUT_DIMENSION, HIDDEN_LAYER_SIZE, HIDDEN_LAYERS_NUM, ALPHABET_SIZE)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "losses = model.train(train_data, optimizer, SEQUENCES_NUM, INPUT_DIMENSION, EPOCHS,CLIPPING_VALUE )\n",
    "\n",
    "print(\"Final Mean loss {}\".format(np.mean(losses)))\n",
    "\n",
    "print( \"============== Infer test data\")\n",
    "for batch in enumerate(test_data):\n",
    "    \n",
    "    true_texts = batch[1]['text']\n",
    "    predicted_texts = model.infer(batch[1]['image'], SEQUENCES_NUM, INPUT_DIMENSION, dataset.alphabet)\n",
    "    \n",
    "    for i in range(0, len(true_texts)):\n",
    "        print(\"Original Text:   {} \\nPredicted Text:  {} \\n\".format(true_texts[i], predicted_texts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:   Byrnhoultz vyll zo backen ind bruwen dat gemall \n",
      "Predicted Text:  AAtmTrMGxTxnE·Ezni·ẽ \n",
      "\n",
      "Original Text:   Man hoerd dayr vyll iamers claegen \n",
      "Predicted Text:  AAAAtvpyku S i nO ẽz \n",
      "\n",
      "Original Text:   Myt gudẽ hertzen dayr zu ſayſſen \n",
      "Predicted Text:  AAAATmmewi· n   gbuG \n",
      "\n",
      "Original Text:   Got wyll dye gud frund geleyden \n",
      "Predicted Text:  AAAvTAGeoo nsO ···e  \n",
      "\n",
      "Original Text:   Vyll roſſmoelen in der ſtat dye fuegen dayr wall \n",
      "Predicted Text:  AAAtiMw WOſ·nJJneDBE \n",
      "\n",
      "Original Text:   Alſo geſament zo ſtrijden \n",
      "Predicted Text:  AAAArSMſy·s· ·cuJVG  \n",
      "\n",
      "Original Text:   Vp maenendaygh hoyrt mych vortan \n",
      "Predicted Text:  AAAmmiBErTnuuS··n··· \n",
      "\n",
      "Original Text:   Gudt zo doyn ind gelucks zo wynſchen \n",
      "Predicted Text:  AAAAſjkkVoeDOSffllS· \n",
      "\n",
      "Original Text:   Den homechtichſten roemſch keyſer \n",
      "Predicted Text:  AAMNy·Nflauuſ iEuuDy \n",
      "\n",
      "Original Text:   Vyll wullengewantz man ouch dayr hauen moyt \n",
      "Predicted Text:  AAAqmAgueT sBE t  ·S \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
