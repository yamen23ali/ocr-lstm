{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ocr_data_loader import *\n",
    "from ocr_utils import *\n",
    "from ocr_image_transformations import *\n",
    "from ocr_model import OCRModel\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "from Levenshtein import distance\n",
    "from ocr_utils import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Predict\n",
    "load a model and get its predictions on the hold out book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628\n",
      "23158\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../../GT4HistOCR/corpus'\n",
    "DATA_SET_NAME = 'RefCorpus-ENHG-Incunabula'\n",
    "HOLDOUT_BOOK = '1499-CronicaCoellen'\n",
    "MODEL_NAME = '17/model_3a20e32bea03553c26a0989a9ff9892d7dcd5918_dict'\n",
    "FRAME_SIZE = 1\n",
    "HIDDEN_LAYER_SIZE = 200\n",
    "HIDDEN_LAYERS_NUM = 3\n",
    "ALPHABET_SIZE = 92\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "MAX_IMAGE_WIDTH=500\n",
    "MAX_IMAGE_HEIGHT=20\n",
    "\n",
    "INPUT_DIMENSION = MAX_IMAGE_HEIGHT * FRAME_SIZE\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    ImageThumbnail(MAX_IMAGE_HEIGHT, MAX_IMAGE_WIDTH),\n",
    "    transforms.ToTensor(),\n",
    "    ImageTensorPadding(MAX_IMAGE_HEIGHT, MAX_IMAGE_WIDTH),\n",
    "    UnfoldImage(1, FRAME_SIZE)\n",
    "])\n",
    "\n",
    "train_data, test_data, holdout_data , dataset = load_data(base_dir = BASE_DIR, dataset_name = DATA_SET_NAME, \n",
    "                                           holdout_book = HOLDOUT_BOOK, transformation=transformation,\n",
    "                                           batch_size=BATCH_SIZE, train_test_split=.8)\n",
    "\n",
    "model = OCRModel(INPUT_DIMENSION, HIDDEN_LAYER_SIZE, HIDDEN_LAYERS_NUM, ALPHABET_SIZE)\n",
    "\n",
    "state_dict = torch.load(f'../../models/RefCorpus-ENHG-Incunabula/{MODEL_NAME}.pth',\n",
    "                       map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "predictions = model.get_predictions(holdout_data, dataset.alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrong_predictions_number(predictions, error_threshold):\n",
    "    wrong = 0\n",
    "    for true_text, predicted_text in zip(predictions['true_texts'], predictions['predicted_texts']):\n",
    "        sample_error = distance(true_text, predicted_text)/ len(true_text)\n",
    "        if sample_error > error_threshold: wrong+=1\n",
    "    \n",
    "    return wrong\n",
    "\n",
    "def calculate_time_saving(samples_number, human_time_per_sample, wrong_predictions, acceptable_error_rate):\n",
    "    human_time_per_sample = 5 # 5 seconds\n",
    "    total_human_time = samples_number*human_time_per_sample\n",
    "\n",
    "    prediction_error_rate = wrong_predictions*100/samples_number\n",
    "    \n",
    "    samples_done_by_human = max(prediction_error_rate - acceptable_error_rate, 0)*samples_number / 100\n",
    "    \n",
    "    human_time = samples_done_by_human * human_time_per_sample\n",
    "    time_saving = (total_human_time - human_time)*100/total_human_time\n",
    "    \n",
    "    return time_saving\n",
    "\n",
    "samples_number = len(predictions['predicted_texts'])\n",
    "acceptable_error_rates = np.arange(0, 22, 1)\n",
    "\n",
    "error_thersholds = np.arange(0, 0.15, 0.02)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "for error_threshold in error_thersholds:\n",
    "    wrong_predictions = get_wrong_predictions_number(predictions, error_threshold)\n",
    "    model_error_rate = wrong_predictions*100/samples_number\n",
    "    print(model_error_rate)\n",
    "    time_savings = []\n",
    "    for acceptable_error_rate in acceptable_error_rates:\n",
    "        time_saving = calculate_time_saving(samples_number, 5, wrong_predictions, acceptable_error_rate)\n",
    "        time_savings.append(int(time_saving))\n",
    "    axs.set_xlabel(\"Acceptable Error Rate %\") \n",
    "    axs.set_ylabel(\"Time Saving %\") \n",
    "    axs.plot(acceptable_error_rates, time_savings, label= f'Error Rate = {format(model_error_rate, \".2f\")}%')\n",
    "    axs.legend(loc='lower right')\n",
    "\n",
    "plt.savefig('time_saving.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "0.726382000092417\n",
      "0.9937453635220709\n"
     ]
    }
   ],
   "source": [
    "texts_confidence = np.array(predictions['texts_confidence'])\n",
    "chars_confidence = np.array(predictions['chars_confidence'])\n",
    "chars = { i: [] for i,char in enumerate(dataset.alphabet) }\n",
    "for item in chars_confidence:\n",
    "    for pair in item:\n",
    "            chars[pair[0]].append(pair[1])\n",
    "print(len(chars))\n",
    "print(texts_confidence.min())\n",
    "print(texts_confidence.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726382000092417\n",
      "0.9937453635220709\n",
      "0.9693175922091773\n"
     ]
    }
   ],
   "source": [
    "print(texts_confidence.min())\n",
    "print(texts_confidence.max())\n",
    "print(np.array(chars[1]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ : nan\n",
      "  : 0.97\n",
      "! : 0.42\n",
      "& : nan\n",
      "( : nan\n",
      ") : nan\n",
      ", : nan\n",
      ". : 0.90\n",
      "/ : 0.88\n",
      "3 : nan\n",
      "4 : nan\n",
      ": : 0.60\n",
      "; : nan\n",
      "? : 0.51\n",
      "A : 0.83\n",
      "B : 0.73\n",
      "C : 0.89\n",
      "D : 0.90\n",
      "E : 0.88\n",
      "F : 0.53\n",
      "G : 0.81\n",
      "H : 0.56\n",
      "I : nan\n",
      "J : 0.91\n",
      "K : nan\n",
      "L : 0.48\n",
      "M : 0.78\n",
      "N : 0.72\n",
      "O : 0.82\n",
      "P : 0.87\n",
      "Q : nan\n",
      "R : 0.66\n",
      "S : 0.85\n",
      "T : 0.75\n",
      "U : nan\n",
      "V : 0.88\n",
      "W : 0.89\n",
      "X : nan\n",
      "Y : 0.37\n",
      "Z : 0.51\n",
      "a : 0.98\n",
      "b : 0.96\n",
      "c : 0.98\n",
      "d : 0.98\n",
      "e : 0.98\n",
      "f : 0.97\n",
      "g : 0.98\n",
      "h : 0.98\n",
      "i : 0.98\n",
      "j : 0.90\n",
      "k : 0.96\n",
      "l : 0.98\n",
      "m : 0.98\n",
      "n : 0.98\n",
      "o : 0.98\n",
      "p : 0.96\n",
      "q : 0.93\n",
      "r : 0.97\n",
      "s : 0.98\n",
      "t : 0.98\n",
      "u : 0.96\n",
      "v : 0.98\n",
      "w : 0.98\n",
      "x : 0.87\n",
      "y : 0.98\n",
      "z : 0.97\n",
      "¶ : 0.90\n",
      "· : 0.85\n",
      "ß : 0.93\n",
      "ã : 0.90\n",
      "ä : nan\n",
      "ð : 0.91\n",
      "ñ : 0.96\n",
      "õ : 0.79\n",
      "ö : 0.44\n",
      "ü : 0.80\n",
      "ÿ : 0.69\n",
      "ĩ : nan\n",
      "ũ : 0.86\n",
      "ů : 0.79\n",
      "ſ : 0.98\n",
      "̃ : 0.56\n",
      "̈ : 0.43\n",
      "ͤ : 0.86\n",
      "ᷣ : 0.62\n",
      "ṽ : nan\n",
      "ẽ : 0.96\n",
      "ỹ : 0.67\n",
      "⸗ : 0.85\n",
      "ꝓ : nan\n",
      "ꝭ : nan\n",
      "ꝰ : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d070867/miniconda3/envs/pjml/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: Mean of empty slice.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for key, value in chars.items():\n",
    "    print(f'{dataset.alphabet[key]} : {format(np.array(value).mean(), \".2f\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "Calculate the confusion matrix on char level and report (Accuracy, Recall, Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "5.0\n",
      "$ : Accuracy 1.00 - Recall nan - Precision nan\n",
      "  : Accuracy 0.94 - Recall 0.84 - Precision 0.83\n",
      "! : Accuracy 1.00 - Recall nan - Precision nan\n",
      "& : Accuracy 1.00 - Recall nan - Precision nan\n",
      "( : Accuracy 1.00 - Recall nan - Precision nan\n",
      ") : Accuracy 1.00 - Recall nan - Precision nan\n",
      ", : Accuracy 1.00 - Recall 0.00 - Precision nan\n",
      ". : Accuracy 0.99 - Recall 0.68 - Precision 0.77\n",
      "/ : Accuracy 1.00 - Recall 0.47 - Precision 0.83\n",
      "3 : Accuracy 1.00 - Recall nan - Precision nan\n",
      "4 : Accuracy 1.00 - Recall nan - Precision nan\n",
      ": : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "; : Accuracy 1.00 - Recall nan - Precision nan\n",
      "? : Accuracy 1.00 - Recall 0.00 - Precision 0.00\n",
      "A : Accuracy 1.00 - Recall 0.64 - Precision 0.79\n",
      "B : Accuracy 1.00 - Recall 0.55 - Precision 0.73\n",
      "C : Accuracy 1.00 - Recall 0.76 - Precision 0.77\n",
      "D : Accuracy 1.00 - Recall 0.73 - Precision 0.71\n",
      "E : Accuracy 1.00 - Recall 0.88 - Precision 0.68\n",
      "F : Accuracy 1.00 - Recall 0.50 - Precision 0.71\n",
      "G : Accuracy 1.00 - Recall 0.70 - Precision 0.58\n",
      "H : Accuracy 1.00 - Recall 0.00 - Precision 0.00\n",
      "I : Accuracy 1.00 - Recall nan - Precision nan\n",
      "J : Accuracy 1.00 - Recall 0.79 - Precision 0.81\n",
      "K : Accuracy 1.00 - Recall 0.00 - Precision nan\n",
      "L : Accuracy 1.00 - Recall 0.20 - Precision 0.25\n",
      "M : Accuracy 1.00 - Recall 0.25 - Precision 0.91\n",
      "N : Accuracy 1.00 - Recall 0.53 - Precision 0.75\n",
      "O : Accuracy 1.00 - Recall 0.91 - Precision 0.77\n",
      "P : Accuracy 1.00 - Recall 0.86 - Precision 0.86\n",
      "Q : Accuracy 1.00 - Recall nan - Precision nan\n",
      "R : Accuracy 1.00 - Recall 0.81 - Precision 0.71\n",
      "S : Accuracy 1.00 - Recall 0.80 - Precision 0.72\n",
      "T : Accuracy 1.00 - Recall 0.38 - Precision 0.75\n",
      "U : Accuracy 1.00 - Recall 0.00 - Precision nan\n",
      "V : Accuracy 1.00 - Recall 0.96 - Precision 0.81\n",
      "W : Accuracy 1.00 - Recall 0.82 - Precision 0.88\n",
      "X : Accuracy 1.00 - Recall nan - Precision nan\n",
      "Y : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "Z : Accuracy 1.00 - Recall 0.00 - Precision 0.00\n",
      "a : Accuracy 0.98 - Recall 0.84 - Precision 0.85\n",
      "b : Accuracy 1.00 - Recall 0.81 - Precision 0.82\n",
      "c : Accuracy 0.99 - Recall 0.84 - Precision 0.83\n",
      "d : Accuracy 0.98 - Recall 0.83 - Precision 0.86\n",
      "e : Accuracy 0.96 - Recall 0.84 - Precision 0.85\n",
      "f : Accuracy 1.00 - Recall 0.88 - Precision 0.88\n",
      "g : Accuracy 0.99 - Recall 0.85 - Precision 0.85\n",
      "h : Accuracy 0.99 - Recall 0.84 - Precision 0.84\n",
      "i : Accuracy 0.98 - Recall 0.84 - Precision 0.81\n",
      "j : Accuracy 1.00 - Recall 0.71 - Precision 0.83\n",
      "k : Accuracy 1.00 - Recall 0.81 - Precision 0.82\n",
      "l : Accuracy 0.99 - Recall 0.86 - Precision 0.84\n",
      "m : Accuracy 0.99 - Recall 0.83 - Precision 0.83\n",
      "n : Accuracy 0.97 - Recall 0.85 - Precision 0.86\n",
      "o : Accuracy 0.99 - Recall 0.83 - Precision 0.82\n",
      "p : Accuracy 1.00 - Recall 0.82 - Precision 0.86\n",
      "q : Accuracy 1.00 - Recall 0.68 - Precision 0.79\n",
      "r : Accuracy 0.98 - Recall 0.82 - Precision 0.85\n",
      "s : Accuracy 1.00 - Recall 0.83 - Precision 0.83\n",
      "t : Accuracy 0.98 - Recall 0.85 - Precision 0.81\n",
      "u : Accuracy 0.99 - Recall 0.85 - Precision 0.83\n",
      "v : Accuracy 0.99 - Recall 0.85 - Precision 0.85\n",
      "w : Accuracy 1.00 - Recall 0.88 - Precision 0.89\n",
      "x : Accuracy 1.00 - Recall 0.58 - Precision 0.76\n",
      "y : Accuracy 0.99 - Recall 0.86 - Precision 0.85\n",
      "z : Accuracy 1.00 - Recall 0.82 - Precision 0.81\n",
      "¶ : Accuracy 1.00 - Recall 0.96 - Precision 0.79\n",
      "· : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "ß : Accuracy 1.00 - Recall 0.93 - Precision 0.78\n",
      "ã : Accuracy 1.00 - Recall 0.79 - Precision 0.71\n",
      "ä : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ð : Accuracy 1.00 - Recall 0.82 - Precision 0.83\n",
      "ñ : Accuracy 1.00 - Recall 0.79 - Precision 0.60\n",
      "õ : Accuracy 1.00 - Recall 1.00 - Precision 1.00\n",
      "ö : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ü : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "ÿ : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "ĩ : Accuracy 1.00 - Recall 0.00 - Precision nan\n",
      "ũ : Accuracy 1.00 - Recall 0.50 - Precision 0.78\n",
      "ů : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "ſ : Accuracy 0.99 - Recall 0.85 - Precision 0.85\n",
      "̃ : Accuracy 1.00 - Recall 0.00 - Precision nan\n",
      "̈ : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ͤ : Accuracy 1.00 - Recall nan - Precision 0.00\n",
      "ᷣ : Accuracy 1.00 - Recall 1.00 - Precision 1.00\n",
      "ṽ : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ẽ : Accuracy 1.00 - Recall 0.85 - Precision 0.73\n",
      "ỹ : Accuracy 1.00 - Recall 0.31 - Precision 0.75\n",
      "⸗ : Accuracy 1.00 - Recall 1.00 - Precision 0.04\n",
      "ꝓ : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ꝭ : Accuracy 1.00 - Recall nan - Precision nan\n",
      "ꝰ : Accuracy 1.00 - Recall 0.00 - Precision nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d070867/miniconda3/envs/pjml/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/d070867/miniconda3/envs/pjml/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# use the blank as padding char since we don't care for it\n",
    "padding_char = '$'\n",
    "\n",
    "chars = { char : i for i,char in enumerate(dataset.alphabet) }\n",
    "\n",
    "confusion = get_confusion_matrix(predictions['true_texts'], predictions['predicted_texts'], chars, padding_char)\n",
    "\n",
    "tp = np.diag(confusion) # True positive\n",
    "fp = confusion.sum(axis=0) - tp # False positive\n",
    "fn = confusion.sum(axis=1) - tp # False negative\n",
    "tn = confusion.trace() - tp # True negative\n",
    "\n",
    "print(confusion[48][52])\n",
    "print(confusion[52][48])\n",
    "for char, i in chars.items():\n",
    "    accuracy = (tp[i] + tn[i])/ (tp[i] + tn[i] + fp[i] + fn[i])\n",
    "    recall = tp[i]/ (tp[i] + fn[i])\n",
    "    precision = tp[i] / (tp[i] + fp[i])\n",
    "    print(f'{char} : Accuracy {format(accuracy, \".2f\")} - Recall {format(recall, \".2f\")} - Precision {format(precision, \".2f\")}')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SET_NAME = 'EarlyModernLatin'\n",
    "HOLDOUT_BOOK = '1483-Decades-Biondo'\n",
    "MODEL_NAME = '1_150_2/model_1_150_2_50_dict'\n",
    "FRAME_SIZE = 1\n",
    "HIDDEN_LAYER_SIZE = 150\n",
    "HIDDEN_LAYERS_NUM = 2\n",
    "ALPHABET_SIZE = 181\n",
    "BATCH_SIZE = 300\n",
    "\n",
    "MAX_IMAGE_WIDTH=1657\n",
    "MAX_IMAGE_HEIGHT=50\n",
    "\n",
    "INPUT_DIMENSION = MAX_IMAGE_HEIGHT * FRAME_SIZE\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    ImageThumbnail(MAX_IMAGE_HEIGHT, MAX_IMAGE_WIDTH),\n",
    "    transforms.ToTensor(),\n",
    "    ImageTensorPadding(MAX_IMAGE_HEIGHT, MAX_IMAGE_WIDTH),\n",
    "    UnfoldImage(1, FRAME_SIZE)\n",
    "])\n",
    "\n",
    "train_data, test_data, holdout_data , dataset = load_data(base_dir = BASE_DIR, dataset_name = DATA_SET_NAME, \n",
    "                                           holdout_book = HOLDOUT_BOOK, transformation=transformation,\n",
    "                                           batch_size=BATCH_SIZE, train_test_split=.8)\n",
    "\n",
    "model = OCRModel(INPUT_DIMENSION, HIDDEN_LAYER_SIZE, HIDDEN_LAYERS_NUM, ALPHABET_SIZE)\n",
    "\n",
    "state_dict = torch.load(f'../../models/EarlyModelLatin/{MODEL_NAME}.pth',\n",
    "                       map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "predictions = model.get_predictions(holdout_data, dataset.alphabet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
